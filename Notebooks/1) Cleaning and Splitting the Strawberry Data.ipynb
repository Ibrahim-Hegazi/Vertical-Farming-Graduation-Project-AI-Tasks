{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7238130-698a-452d-b794-0d7c2ffcb495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (8.3.80)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ibrahim_hegazi\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e94f79b-fe41-415c-a2ee-098ac62dacc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23216674-4691-41ca-9798-303d6ae3c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "def convert_csv_to_yolo_seg(csv_path, output_labels_dir, class_mapping, dataset_base_path):\n",
    "    \"\"\"\n",
    "    Convert CSV annotations to YOLOv8-seg format.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing annotations.\n",
    "        output_labels_dir (str): Directory to save YOLO format label files.\n",
    "        class_mapping (dict): Mapping of class names to class IDs.\n",
    "        dataset_base_path (str): Base path to prepend to relative paths in the CSV.\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_labels_dir, exist_ok=True)\n",
    "\n",
    "    with open(csv_path, \"r\") as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            # Construct absolute paths\n",
    "            image_path = os.path.join(dataset_base_path, row[\"image_path\"])\n",
    "            mask_path = os.path.join(dataset_base_path, row[\"mask_path\"])\n",
    "            label = row[\"label\"]\n",
    "\n",
    "            # Get image dimensions\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Warning: Image not found at {image_path}\")\n",
    "                continue\n",
    "            image_height, image_width = image.shape[:2]\n",
    "\n",
    "            # Read mask (assuming mask is a binary image)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                print(f\"Warning: Mask not found at {mask_path}\")\n",
    "                continue\n",
    "\n",
    "            # Find contours in the mask\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Prepare YOLO-seg annotation\n",
    "            yolo_annotation = []\n",
    "            for contour in contours:\n",
    "                # Simplify contour to polygon points\n",
    "                polygon_points = contour.squeeze().tolist()\n",
    "                if len(polygon_points) < 3:  # Skip invalid polygons\n",
    "                    continue\n",
    "\n",
    "                # Normalize polygon points\n",
    "                normalized_points = []\n",
    "                for x, y in polygon_points:\n",
    "                    normalized_x = x / image_width\n",
    "                    normalized_y = y / image_height\n",
    "                    normalized_points.extend([normalized_x, normalized_y])\n",
    "\n",
    "                # Add class ID and normalized points to annotation\n",
    "                yolo_annotation.append(f\"{class_mapping[label]} \" + \" \".join(map(str, normalized_points)))\n",
    "\n",
    "            # Save YOLO-seg annotation to file\n",
    "            if yolo_annotation:\n",
    "                output_txt_path = os.path.join(output_labels_dir, os.path.basename(image_path).replace(\".jpg\", \".txt\"))\n",
    "                with open(output_txt_path, \"w\") as f:\n",
    "                    f.write(\"\\n\".join(yolo_annotation))\n",
    "\n",
    "# Example usage\n",
    "dataset_base_path = \"C:\\\\Users\\\\Ibrahim_Hegazi\\\\Desktop\\\\Graduation_Project\\\\dataset\"\n",
    "csv_path = os.path.join(dataset_base_path, \"labels.csv\")\n",
    "output_labels_dir = os.path.join(dataset_base_path, \"labels\")\n",
    "class_mapping = {'angular_leafspot':0,\n",
    "'anthracnose_fruit_rot':1,\n",
    "'blossom_blight':2,\n",
    "'gray_mold':3,\n",
    "'leaf_spot':4,\n",
    "'powdery_mildew_fruit':5,\n",
    "'powdery_mildew_leaf':6\n",
    "}  # Map labels to class IDs\n",
    "\n",
    "convert_csv_to_yolo_seg(csv_path, output_labels_dir, class_mapping, dataset_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c8a7e9e-e239-417e-8e09-ac3f21887d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access granted: C:\\Users\\Ibrahim_Hegazi\\Desktop\\Graduation_Project\\dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"C:\\\\Users\\\\Ibrahim_Hegazi\\\\Desktop\\\\Graduation_Project\\\\dataset\"\n",
    "if not os.access(dataset_path, os.R_OK | os.W_OK):\n",
    "    print(f\"Permission denied: {dataset_path}\")\n",
    "else:\n",
    "    print(f\"Access granted: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b99aa7-8f6f-4f0c-8f24-c903f5d202ff",
   "metadata": {},
   "source": [
    "# Script for Stratified Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "682af6fa-514a-48ce-aa8a-b9a4fdec6993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "def split_dataset(dataset_path, train_ratio=0.8):\n",
    "    images_dir = os.path.join(dataset_path, \"images\")\n",
    "    labels_dir = os.path.join(dataset_path, \"labels\")\n",
    "    train_dir = os.path.join(dataset_path, \"train\")\n",
    "    val_dir = os.path.join(dataset_path, \"val\")\n",
    "\n",
    "    # Create train and val directories\n",
    "    os.makedirs(os.path.join(train_dir, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(train_dir, \"labels\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, \"labels\"), exist_ok=True)\n",
    "\n",
    "    # Group images by class\n",
    "    class_to_images = defaultdict(list)\n",
    "    image_files = [f for f in os.listdir(images_dir) if f.endswith(\".jpg\")]\n",
    "\n",
    "    for img_file in image_files:\n",
    "        label_file = img_file.replace(\".jpg\", \".txt\")\n",
    "        label_path = os.path.join(labels_dir, label_file)\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                if lines:\n",
    "                    # Assuming the first line contains the class ID\n",
    "                    class_id = lines[0].split()[0]\n",
    "                    class_to_images[class_id].append((img_file, label_file))\n",
    "\n",
    "    # Split each class into train and val\n",
    "    for class_id, images in class_to_images.items():\n",
    "        random.shuffle(images)\n",
    "        split_idx = int(len(images) * train_ratio)\n",
    "        train_images = images[:split_idx]\n",
    "        val_images = images[split_idx:]\n",
    "\n",
    "        # Move train images and labels\n",
    "        for img_file, label_file in train_images:\n",
    "            shutil.move(os.path.join(images_dir, img_file), os.path.join(train_dir, \"images\", img_file))\n",
    "            shutil.move(os.path.join(labels_dir, label_file), os.path.join(train_dir, \"labels\", label_file))\n",
    "\n",
    "        # Move val images and labels\n",
    "        for img_file, label_file in val_images:\n",
    "            shutil.move(os.path.join(images_dir, img_file), os.path.join(val_dir, \"images\", img_file))\n",
    "            shutil.move(os.path.join(labels_dir, label_file), os.path.join(val_dir, \"labels\", label_file))\n",
    "\n",
    "# Example usage\n",
    "dataset_path = \"C:\\\\Users\\\\Ibrahim_Hegazi\\\\Desktop\\\\Graduation_Project\\\\dataset\"\n",
    "split_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697c7e26-d79a-4cb9-af3e-13676d0e64c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ibrahim_Hegazi\\Desktop\\Graduation_Project\\dataset\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\\\Users\\\\Ibrahim_Hegazi\\\\Desktop\\\\Graduation_Project\\\\dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db60c469-55e1-422d-a102-f85e32ea6c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations\n",
      "dataset.yaml\n",
      "labels.csv\n",
      "masks\n",
      "runs\n",
      "train\n",
      "val\n",
      "yolov8n-seg.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List all files and directories in the current directory\n",
    "files = os.listdir()\n",
    "\n",
    "# Print the files\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228fd2f3-e1ae-4725-82bd-c8d20e592bb6",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e094bfe-0bfb-4676-a3f2-e75326b0c617",
   "metadata": {},
   "source": [
    "## Training the model Could not be done here due to my hardware capabilities, I will run the Training Code on Kaggle Notebooks and i will provide the code later on in another notebook if you are intersted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8510458-6dec-44be-ba0c-3a500e7d261b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f5bb0-3c2b-41ac-8f5d-c3ce1a9a926c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe60615-5a21-43e5-8823-0ae749d84036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2010bb2-a7a2-40b8-829c-262eeefeac07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
